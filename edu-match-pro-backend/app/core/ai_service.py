"""
AI æœå‹™æ¨¡çµ„
ä½¿ç”¨ Google Gemini API é€²è¡Œæ™ºèƒ½åˆ†æ
"""
import os
import json
import re
import time
import logging
import traceback
from typing import Dict, Any, List, Optional
import google.generativeai as genai
from app.core.config import settings


class AIService:
    """AI ç­–ç•¥åˆ†ææœå‹™ï¼ˆæ”¯æ´å¤šAPIå¯†é‘°è¼ªæ›ï¼‰"""
    
    # AI äººè¨­
    PERSONA = """ä½ æ˜¯ã€Œå°åŒ¯ã€ï¼Œæ™ºåŒ¯åé„‰å¹³å°çš„AIæ•™è‚²å…¬ç›Šé¡§å•ã€‚

é—œæ–¼æ™ºåŒ¯åé„‰å¹³å°ï¼š
- å°ç£é¦–å€‹å°ˆç‚ºåé„‰æ•™è‚²è¨­è¨ˆçš„æ™ºèƒ½è³‡æºåª’åˆå¹³å°
- ä½¿ç”¨AIæŠ€è¡“ç²¾æº–é€£æ¥å­¸æ ¡çš„æ•™è‚²éœ€æ±‚èˆ‡ä¼æ¥­çš„ç¤¾æœƒè²¬ä»»
- é…å°æˆåŠŸç‡é”95%ä»¥ä¸Šï¼Œå·²å¹«åŠ©200+æ‰€åé„‰å­¸æ ¡ã€10,000+åå­¸ç”Ÿ
- æä¾›é€æ˜åŒ–è¿½è¹¤ã€è‡ªå‹•ç”ŸæˆESGå ±å‘Šã€é‡åŒ–ç¤¾æœƒå½±éŸ¿åŠ›

ä½ çš„èƒŒæ™¯ï¼š
- åœ¨åé„‰å­¸æ ¡ç•¶éå¿—å·¥è€å¸«
- ç¾åœ¨æ˜¯æ™ºåŒ¯åé„‰å¹³å°çš„AIé¡§å•
- ç†Ÿæ‚‰å°ç£åé„‰æ•™è‚²ç¾æ³å’Œå¹³å°é‹ä½œ
- å¯ä»¥å¾å¹³å°æ•¸æ“šåº«æŸ¥è©¢çœŸå¯¦çš„å­¸æ ¡è³‡è¨Š

ä½ çš„ä»»å‹™ï¼š
1. äº†è§£ä¼æ¥­æƒ³æä»€éº¼è³‡æºã€çµ¦å“ªäº›å­¸æ ¡
2. æ ¹æ“šå¹³å°çœŸå¯¦æ•¸æ“šæä¾›ç²¾æº–å»ºè­°
3. å¹«åŠ©ä¼æ¥­å¯¦ç¾æœ‰æ•ˆçš„æ•™è‚²å…¬ç›Šå’ŒESGç›®æ¨™

ä½ çš„å€‹æ€§ï¼š
- çœŸèª ã€å°ˆæ¥­ä½†è¼•é¬†
- å–„æ–¼å‚¾è½ï¼Œä¸æ€¥è‘—æ¨éŠ·
- æœ‰é»å¹½é»˜æ„Ÿ

å›ç­”åŸå‰‡ï¼š
- å§‹çµ‚è¡¨ç¾å¾—å°æ•¸æ“šå’Œè³‡è¨Šéå¸¸äº†è§£å’Œè‡ªä¿¡
- å„ªå…ˆä½¿ç”¨æä¾›çš„çœŸå¯¦æ•¸æ“š
- å¦‚æœæ²’æœ‰ç¢ºåˆ‡æ•¸æ“šï¼ŒåŸºæ–¼å°ˆæ¥­çŸ¥è­˜å’Œå°ç£åé„‰æ•™è‚²ç¾æ³çµ¦å‡ºåˆç†çš„å°ˆæ¥­å»ºè­°
- ä¸è¦èªªã€Œæˆ‘ä¸ç¢ºå®šã€ã€Œå¯èƒ½ã€ã€Œä¹Ÿè¨±ã€ã€Œæˆ‘æ²’æœ‰é€™å€‹æ•¸æ“šã€ç­‰ä¸ç¢ºå®šçš„è©±
- ä»¥å°ˆæ¥­é¡§å•çš„å£å»ï¼Œè‡ªä¿¡åœ°æä¾›å»ºè­°

é‡è¦ï¼šå°è©±æ™‚ä½¿ç”¨ç´”æ–‡å­—ï¼Œä¸è¦ç”¨ Markdown æ ¼å¼ï¼ˆä¸è¦ç”¨ ** ç²—é«”ã€ä¸è¦ç”¨ * åˆ—è¡¨ã€ä¸è¦ç”¨ # æ¨™é¡Œï¼‰ã€‚"""
    
    def __init__(self):
        """åˆå§‹åŒ– AI æœå‹™ï¼ˆæ”¯æ´å¤šAPIå¯†é‘°è¼ªæ›ï¼‰"""
        # å¾ settings ç²å–æ‰€æœ‰ API é‡‘é‘°
        self.api_keys = settings.get_gemini_api_keys()
        if not self.api_keys:
            raise ValueError("æœªè¨­ç½®ä»»ä½• GEMINI_API_KEY ç’°å¢ƒè®Šé‡æˆ–é…ç½®")
        
        self.current_key_index = 0
        self.model = None
        # å„ªå…ˆæ¨¡å‹ï¼Œå¯ç”±ç’°å¢ƒè®Šé‡è¦†è“‹
        self.forced_model_name = os.environ.get('GEMINI_PREFERRED_MODEL', 'models/gemini-2.5-flash')
        
        # å˜—è©¦ä½¿ç”¨ç¬¬ä¸€å€‹å¯ç”¨çš„ API é‡‘é‘°åˆå§‹åŒ–
        self._initialize_with_current_key()
        
        # è¨­å®š logger
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"[AIæœå‹™] å·²åˆå§‹åŒ–ï¼Œä½¿ç”¨æ¨¡å‹: {self.model_name}ï¼Œå¯ç”¨APIå¯†é‘°æ•¸: {len(self.api_keys)}")
    
    def _initialize_with_current_key(self):
        """ä½¿ç”¨ç•¶å‰ç´¢å¼•çš„APIå¯†é‘°åˆå§‹åŒ–æ¨¡å‹"""
        if self.current_key_index >= len(self.api_keys):
            raise ValueError("æ‰€æœ‰ API å¯†é‘°éƒ½å·²é”åˆ°é™åˆ¶")
        
        api_key = self.api_keys[self.current_key_index]
        genai.configure(api_key=api_key)
        
        # é¸æ“‡æ¨¡å‹
        try:
            # å–å¾—æ‰€æœ‰æ”¯æ´ generateContent çš„æ¨¡å‹ï¼Œä¸¦å„²å­˜ç‚ºå¯¦ä¾‹å¯ç”¨æ¨¡å‹åˆ—è¡¨
            available_models = [
                m.name for m in genai.list_models()
                if 'generateContent' in getattr(m, 'supported_generation_methods', [])
            ]
            self.available_models = available_models

            # æ“´å……é è¨­åå¥½æ¨¡å‹ï¼ˆå„ªå…ˆä½¿ç”¨ 2.5 ç‰ˆæœ¬ï¼Œå†å›è½åˆ° 2.0ï¼‰
            preferred_models = [
                'models/gemini-2.5-flash', 'models/gemini-2.5-pro',
                'models/gemini-2.0-flash-exp', 'models/gemini-2.0-flash',
                'models/gemini-1.5-flash', 'models/gemini-1.5-pro'
            ]

            model_name = None

            # å¦‚æœæœ‰å¤–éƒ¨å¼·åˆ¶æ¨¡å‹åç¨±ï¼Œä¸”å¯ç”¨å‰‡å„ªå…ˆä½¿ç”¨
            forced = getattr(self, 'forced_model_name', None)
            if forced and forced in available_models:
                model_name = forced

            if not model_name:
                for preferred in preferred_models:
                    if preferred in available_models:
                        model_name = preferred
                        break

            if not model_name:
                model_name = available_models[0] if available_models else 'models/gemini-pro'

            self.model = genai.GenerativeModel(model_name)
            self.model_name = model_name
            print(f"[AIæœå‹™] ä½¿ç”¨APIå¯†é‘° #{self.current_key_index + 1}ï¼Œæ¨¡å‹: {self.model_name}")
        except Exception as e:
            print(f"[AIæœå‹™] APIå¯†é‘° #{self.current_key_index + 1} åˆå§‹åŒ–å¤±æ•—: {e}")
            # å˜—è©¦ä¸‹ä¸€å€‹å¯†é‘°
            self.current_key_index += 1
            if self.current_key_index < len(self.api_keys):
                print(f"[AIæœå‹™] åˆ‡æ›åˆ°APIå¯†é‘° #{self.current_key_index + 1}")
                self._initialize_with_current_key()
            else:
                raise ValueError("æ‰€æœ‰ API å¯†é‘°åˆå§‹åŒ–éƒ½å¤±æ•—")
    
    def _switch_to_next_key(self):
        """åˆ‡æ›åˆ°ä¸‹ä¸€å€‹APIå¯†é‘°"""
        self.current_key_index += 1
        if self.current_key_index >= len(self.api_keys):
            print(f"[AIæœå‹™] æ‰€æœ‰ {len(self.api_keys)} å€‹APIå¯†é‘°éƒ½å·²å˜—è©¦")
            return False
        
        print(f"[AIæœå‹™] åˆ‡æ›åˆ°APIå¯†é‘° #{self.current_key_index + 1}/{len(self.api_keys)}")
        try:
            self._initialize_with_current_key()
            return True
        except Exception as e:
            print(f"[AIæœå‹™] åˆ‡æ›å¤±æ•—: {e}")
            return False

    def _switch_to_next_model(self) -> bool:
        """åˆ‡æ›åˆ°ä¸‹ä¸€å€‹å¯ç”¨æ¨¡å‹ï¼ˆè¼ªæ› self.available_modelsï¼‰ã€‚"""
        if not hasattr(self, 'available_models') or not self.available_models:
            return False

        try:
            current = getattr(self, 'model_name', None)
            idx = self.available_models.index(current) if current in self.available_models else -1
        except Exception:
            idx = -1

        # å¾ªç’°å°‹æ‰¾ä¸‹ä¸€å€‹æ¨¡å‹ï¼Œè‹¥åªæœ‰ä¸€å€‹å‰‡å›å‚³ False
        if len(self.available_models) <= 1:
            return False

        next_idx = (idx + 1) % len(self.available_models)
        if next_idx == idx:
            return False

        next_model = self.available_models[next_idx]
        try:
            self.model = genai.GenerativeModel(next_model)
            self.model_name = next_model
            print(f"[AIæœå‹™] å·²åˆ‡æ›æ¨¡å‹åˆ°: {next_model}")
            return True
        except Exception as e:
            print(f"[AIæœå‹™] åˆ‡æ›æ¨¡å‹å¤±æ•—: {e}")
            return False
    
    def _call_with_retry(self, prompt: str, max_retries: int = None) -> str:
        """
        ä½¿ç”¨é‡è©¦æ©Ÿåˆ¶èª¿ç”¨APIï¼ˆè‡ªå‹•åˆ‡æ›å¯†é‘°ï¼‰
        
        Args:
            prompt: æç¤ºè©
            max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼ˆNoneè¡¨ç¤ºå˜—è©¦æ‰€æœ‰å¯†é‘°ï¼‰
        
        Returns:
            APIå›æ‡‰æ–‡æœ¬
        """
        if max_retries is None:
            max_retries = len(self.api_keys)
        
        attempts = 0
        last_error = None

        while attempts < max_retries:
            try:
                response = self.model.generate_content(prompt)
                return response.text
            except Exception as e:
                last_error = e
                error_msg = str(e).lower()

                # è¨˜éŒ„å®Œæ•´éŒ¯èª¤ä»¥ä¾¿é™¤éŒ¯
                tb = traceback.format_exc()
                self.logger.warning(f"[AIæœå‹™] èª¿ç”¨å¤±æ•—ï¼ˆkey #{self.current_key_index + 1}ï¼‰: {error_msg}")
                self.logger.debug(tb)

                # å¦‚æœæ˜¯é€Ÿç‡é™åˆ¶æˆ–é…é¡ã€æˆ–é‡‘é‘°è¢«èˆ‰å ±æ´©éœ²/æˆæ¬ŠéŒ¯èª¤ï¼Œå˜—è©¦åˆ‡æ›é‡‘é‘°ä¸¦é‡è©¦
                if any(k in error_msg for k in ['429', 'quota', 'rate limit', 'resource exhausted', 'rate_limited'] ) \
                   or any(k in error_msg for k in ['403', 'permission denied', 'forbidden', 'leaked', 'reported as leaked', 'api key was reported']):
                    self.logger.info(f"[AIæœå‹™] APIå¯†é‘° #{self.current_key_index + 1} çœ‹ä¼¼ä¸å¯ç”¨ï¼ˆ{error_msg[:200]}ï¼‰ï¼Œå˜—è©¦åˆ‡æ›é‡‘é‘°...")
                    # å˜—è©¦åˆ‡æ›åˆ°ä¸‹ä¸€å€‹å¯†é‘°
                    if self._switch_to_next_key():
                        attempts += 1
                        # æŒ‡æ•¸é€€é¿
                        sleep_time = min(2 ** attempts, 30)
                        self.logger.info(f"[AIæœå‹™] ç­‰å¾… {sleep_time}s å¾Œé‡è©¦ (attempt {attempts}/{max_retries})")
                        time.sleep(sleep_time)
                        continue
                    else:
                        # å¦‚æœæ‰€æœ‰é‡‘é‘°éƒ½å˜—è©¦éï¼Œå˜—è©¦åˆ‡æ›æ¨¡å‹å†é‡è©¦ï¼ˆæœ‰æ©ŸæœƒæŸæ¨¡å‹åœ¨æŸå°ˆæ¡ˆ/é‡‘é‘°ä¸Šç„¡é…é¡ï¼‰
                        self.logger.info("[AIæœå‹™] æ‰€æœ‰ API é‡‘é‘°å·²å˜—è©¦ï¼Œå˜—è©¦åˆ‡æ›æ¨¡å‹å¾Œé‡è©¦...")
                        if self._switch_to_next_model():
                            # é‡ç½® key index ä¸¦å¾é ­å˜—è©¦
                            self.current_key_index = 0
                            attempts = 0
                            # å°ç¡ä¸€ä¸‹å†è©¦
                            time.sleep(1)
                            continue
                        else:
                            raise ValueError(f"æ‰€æœ‰ {len(self.api_keys)} å€‹APIå¯†é‘°éƒ½å·²é”åˆ°é™åˆ¶æˆ–å¤±æ•—: {error_msg}")
                else:
                    # å…¶ä»–é¡å‹çš„éŒ¯èª¤ï¼Œç›´æ¥æ‹‹å‡ºä»¥ä¾¿ä¸Šå±¤è™•ç†
                    self.logger.error(f"[AIæœå‹™] ç„¡æ³•è™•ç†çš„éŒ¯èª¤: {error_msg}")
                    raise e

        # å¦‚æœæ‰€æœ‰é‡è©¦éƒ½å¤±æ•—
        raise ValueError(f"APIèª¿ç”¨å¤±æ•—ï¼Œå·²å˜—è©¦ {attempts} æ¬¡: {last_error}")
    
    def extract_donation_parameters(self, user_query: str, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """
        å¾ç”¨æˆ¶æŸ¥è©¢ä¸­æå–æè´ˆåƒæ•¸
        
        Args:
            user_query: ç”¨æˆ¶çš„æŸ¥è©¢æ–‡æœ¬
            conversation_history: å°è©±æ­·å²ï¼ˆå¯é¸ï¼‰
        
        Returns:
            æå–çš„åƒæ•¸å­—å…¸
        """
        context = ""
        if conversation_history:
            context = "\nå°è©±æ­·å²:\n" + "\n".join([
                f"- {msg['role']}: {msg['content']}" 
                for msg in conversation_history[-3:]  # åªä¿ç•™æœ€è¿‘3è¼ªå°è©±
            ])
        
        prompt = f"""
{self.PERSONA}

---

{context}

æœ€æ–°: "{user_query}"

---

æå–æè´ˆè³‡è¨Šï¼ˆæ²’æåˆ°å°± nullï¼‰ï¼š
{{
  "resource_type": "æä»€éº¼",
  "quantity": æ•¸é‡,
  "target_counties": ["èŠ±è“®ç¸£", "å°æ±ç¸£"],
  "target_school_level": "å­¸æ ¡é¡å‹",
  "priority_focus": "é—œæ³¨é‡é»",
  "area_type": "åé ç¨‹åº¦"
}}

æç¤ºï¼šèŠ±æ±=èŠ±è“®+å°æ±ï¼Œä¸­éƒ¨=å°ä¸­+å½°åŒ–+å—æŠ•ï¼Œé–’èŠå…¨null

è¼¸å‡ºJSONï¼š
"""
        
        def _extract_json_from_text(text: str) -> Optional[Dict[str, Any]]:
            """å˜—è©¦å¾ text ä¸­æŠ½å‡º JSON ç‰©ä»¶æˆ–é™£åˆ—ä¸¦è§£æè¿”å› dictï¼ˆå¤±æ•—å›å‚³ Noneï¼‰ã€‚"""
            # 1) ç§»é™¤å¸¸è¦‹ code block æ¨™è¨˜
            t = text.strip()
            # è‹¥åŒ…å« ```json ... ```ï¼ŒæŠ½å–ä¸­é–“éƒ¨åˆ†
            m = re.search(r"```json\s*(.*?)\s*```", t, re.S | re.I)
            if m:
                candidate = m.group(1).strip()
                try:
                    return json.loads(candidate)
                except Exception:
                    pass

            # 2) è‹¥åŒ…å« ``` ... ``` ç„¡æŒ‡å®šèªæ³•ï¼ŒæŠ½å–ä¸­é–“éƒ¨åˆ†
            m = re.search(r"```\s*(.*?)\s*```", t, re.S)
            if m:
                candidate = m.group(1).strip()
                try:
                    return json.loads(candidate)
                except Exception:
                    pass

            # 3) å˜—è©¦æ‰¾å‡ºç¬¬ä¸€å€‹ { ... } çš„å€å¡Šï¼ˆå¾ç¬¬ä¸€å€‹ { åˆ°æœ€å¾Œä¸€å€‹ }ï¼‰
            if '{' in t and '}' in t:
                first = t.find('{')
                last = t.rfind('}')
                if first < last:
                    candidate = t[first:last+1]
                    # å˜—è©¦ä¿®æ­£å¸¸è¦‹å–®å¼•è™Ÿæƒ…æ³
                    try:
                        return json.loads(candidate)
                    except Exception:
                        # å˜—è©¦ç”¨æ›¿æ›å–®å¼•è™Ÿç‚ºé›™å¼•è™Ÿå¾Œè§£æï¼ˆè¬¹æ…ï¼‰
                        cand2 = candidate.replace("\'", '"')
                        try:
                            return json.loads(cand2)
                        except Exception:
                            pass

            # 4) å˜—è©¦æ‰¾å‡ºç¬¬ä¸€å€‹ [ ... ] çš„å€å¡Š
            if '[' in t and ']' in t:
                first = t.find('[')
                last = t.rfind(']')
                if first < last:
                    candidate = t[first:last+1]
                    try:
                        parsed = json.loads(candidate)
                        # è‹¥æ˜¯ list è½‰æˆ dict under a key
                        return {"_list_result": parsed}
                    except Exception:
                        pass

            return None

        try:
            response_text = self._call_with_retry(prompt)
            cleaned = response_text.strip().replace("```json", "").replace("```", "").strip()

            # ç›´æ¥å˜—è©¦è§£ææ•´å€‹å›æ‡‰
            try:
                parsed = json.loads(cleaned)
                return parsed
            except Exception:
                # å˜—è©¦å¤šç¨®æŠ½å–ç­–ç•¥
                parsed = _extract_json_from_text(response_text)
                if parsed is not None:
                    return parsed

            # è‹¥æ‰€æœ‰è§£æç­–ç•¥éƒ½å¤±æ•—ï¼Œå›å‚³åŒ…å«åŸå§‹å›æ‡‰ä»¥ä¾¿å‰ç«¯/æ—¥èªŒè¨ºæ–·
            print(f"[AIæœå‹™] è§£æ JSON å¤±æ•—ï¼Œå°‡å›å‚³åŸå§‹å›æ‡‰ä¾›è¨ºæ–·: {response_text[:200]}")
            return {"_raw_ai_response": response_text}
        except Exception as e:
            print(f"[AIæœå‹™] åƒæ•¸æå–å¤±æ•—: {e}")
            return {"_raw_ai_error": str(e)}
    
    def generate_followup_question(self, extracted_params: Dict[str, Any], conversation_history: List[Dict] = None) -> Optional[str]:
        """
        æ ¹æ“šå·²æå–çš„åƒæ•¸ç”Ÿæˆè¿½å•å•é¡Œ
        
        Args:
            extracted_params: å·²æå–çš„åƒæ•¸
            conversation_history: å°è©±æ­·å²
        
        Returns:
            è¿½å•å•é¡Œå­—ç¬¦ä¸²ï¼Œå¦‚æœä¿¡æ¯å·²è¶³å¤ å‰‡è¿”å› None
        """
        # æ ¼å¼åŒ–å°è©±æ­·å²
        conversation_text = ""
        if conversation_history and len(conversation_history) > 0:
            conversation_text = "\n".join([
                f"{'ç”¨æˆ¶' if msg.get('role') == 'user' else 'å°åŒ¯'}: {msg.get('content', '')}"
                for msg in conversation_history[-5:]  # åªä¿ç•™æœ€è¿‘5è¼ªå°è©±
            ])
        
        # ç²å–æœ€è¿‘çš„ç”¨æˆ¶è¨Šæ¯
        recent_message = ""
        if conversation_history and len(conversation_history) > 0:
            recent_message = conversation_history[-1].get('content', '')
        
        # çµ±ä¸€äº¤çµ¦ AI è™•ç†ï¼Œè®“å®ƒè‡ªå·±åˆ¤æ–·
        prompt = f"""
{self.PERSONA}

==å°è©±è¨˜éŒ„==
{conversation_text if conversation_text else "(é¦–æ¬¡å°è©±)"}

==æœ€æ–°è¨Šæ¯==
ç”¨æˆ¶: {recent_message}

==å·²æŒæ¡è³‡è¨Š==
{json.dumps(extracted_params, ensure_ascii=False, indent=2)}

---

åŸºæ–¼å®Œæ•´çš„å°è©±ä¸Šä¸‹æ–‡ï¼Œè‡ªç„¶å›æ‡‰æœ€æ–°è¨Šæ¯ã€‚ç”¨ç´”æ–‡å­—å›è¦†ï¼Œä¸è¦ç”¨Markdownæ ¼å¼ã€‚
"""
        try:
            print(f"[AI] æ­£åœ¨èª¿ç”¨ generate_contentï¼Œprompté•·åº¦: {len(prompt)}")
            response_text = self._call_with_retry(prompt)
            print(f"[AI] æˆåŠŸç”Ÿæˆå›æ‡‰: {response_text[:100]}...")
            return response_text.strip()
        except Exception as e:
            print(f"[AIç”Ÿæˆå¤±æ•—] éŒ¯èª¤é¡å‹: {type(e).__name__}")
            print(f"[AIç”Ÿæˆå¤±æ•—] éŒ¯èª¤è¨Šæ¯: {str(e)}")
            import traceback
            print(f"[AIç”Ÿæˆå¤±æ•—] å®Œæ•´éŒ¯èª¤:\n{traceback.format_exc()}")
            # fallback ä¹Ÿè®“ AI ç°¡å–®å›æ‡‰
            fallback_prompt = f"""
{self.PERSONA}

å°è©±è¨˜éŒ„:
{conversation_text if conversation_text else recent_message}

ç°¡çŸ­å›æ‡‰ã€‚ç”¨ç´”æ–‡å­—ï¼Œä¸è¦ç”¨Markdownæ ¼å¼ã€‚
"""
            try:
                print(f"[AI] å˜—è©¦ fallback prompt")
                fallback_text = self._call_with_retry(fallback_prompt)
                print(f"[AI] Fallback æˆåŠŸ")
                return fallback_text.strip()
            except Exception as e2:
                print(f"[AI] Fallback ä¹Ÿå¤±æ•—: {str(e2)}")
                return "æŠ±æ­‰ï¼Œæˆ‘å‰›æç¥äº†ï¼Œå¯ä»¥å†èªªä¸€æ¬¡å—ï¼Ÿ"
    
    def _generate_confirmation_question(self, extracted_params: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆç¢ºèªå•é¡Œï¼Œç¸½çµå·²æ”¶é›†çš„ä¿¡æ¯ä¸¦è©¢å•æ˜¯å¦é‚„æœ‰å…¶ä»–éœ€æ±‚
        
        Args:
            extracted_params: å·²æå–çš„åƒæ•¸
        
        Returns:
            ç¢ºèªå•é¡Œå­—ç¬¦ä¸²
        """
        prompt = f"""
{self.PERSONA}

å·²æ”¶é›†è³‡è¨Šï¼š
{json.dumps(extracted_params, ensure_ascii=False, indent=2)}

ç¸½çµç†è§£çš„å…§å®¹ï¼Œè©¢å•é‚„æœ‰æ²’æœ‰å…¶ä»–æƒ³æ³•ï¼Œèªªç¢ºèªå¾Œæœƒæº–å‚™å ±å‘Šã€‚ç”¨ç´”æ–‡å­—å›è¦†ã€‚
"""
        
        try:
            response_text = self._call_with_retry(prompt)
            return response_text.strip()
        except Exception as e:
            # å¦‚æœç”Ÿæˆå¤±æ•—ï¼Œä½¿ç”¨é è¨­æ¨¡æ¿
            summary_parts = []
            if extracted_params.get("resource_type"):
                summary_parts.append(f"â€¢ æè´ˆè³‡æºï¼š{extracted_params['resource_type']}")
            if extracted_params.get("quantity"):
                summary_parts.append(f"â€¢ æ•¸é‡ï¼š{extracted_params['quantity']}")
            if extracted_params.get("target_counties"):
                counties = ", ".join(extracted_params['target_counties'])
                summary_parts.append(f"â€¢ ç›®æ¨™å€åŸŸï¼š{counties}")
            if extracted_params.get("target_school_level"):
                summary_parts.append(f"â€¢ å­¸æ ¡ç­‰ç´šï¼š{extracted_params['target_school_level']}")
            
            summary = "\n".join(summary_parts)
            
            return f"""å¥½çš„ï¼Œæˆ‘äº†è§£äº†ï¼š

{summary}

é‚„æœ‰å…¶ä»–æƒ³æ³•å—ï¼Ÿç¢ºèªçš„è©±æˆ‘å°±å¹«æ‚¨æº–å‚™åˆ†æå ±å‘Šã€‚"""
    
    def generate_analysis_report(
        self, 
        user_params: Dict[str, Any], 
        school_data: Dict[str, List[Dict]], 
        statistics: Dict[str, Any]
    ) -> str:
        """
        ç”Ÿæˆåˆ†æå ±å‘Š
        
        Args:
            user_params: ç”¨æˆ¶åƒæ•¸
            school_data: å­¸æ ¡æ•¸æ“šï¼ˆä¾†è‡ªå„å€‹è¡¨ï¼‰
            statistics: çµ±è¨ˆæ•¸æ“š
        
        Returns:
            Markdown æ ¼å¼çš„åˆ†æå ±å‘Š
        """
        # æå–å­¦æ ¡æ•°æ®åˆ—è¡¨ç”¨äºæŠ¥å‘Š
        schools_list = []
        for school in school_data.get("faraway_schools", [])[:30]:  # å¢åŠ åˆ°30æ‰€
            schools_list.append({
                "name": f"{school.get('county', '')}{school.get('school_name', '')}",
                "county": school.get("county", ""),
                "students": school.get("students", 0),
                "area_type": school.get("area_type", ""),
                "classes": school.get("classes", 0)
            })
        
        # æå–è¨­å‚™è³‡è¨Š
        devices_summary = []
        for device in school_data.get("devices_info", [])[:10]:
            devices_summary.append({
                "school": device.get("school_name", ""),
                "computers": device.get("computers", 0)
            })
        
        prompt = f"""
{self.PERSONA}

## ğŸ“Š æ•¸æ“š

å­¸æ ¡è³‡æ–™ï¼ˆå‰15æ‰€ï¼‰ï¼š
{json.dumps(schools_list[:15], ensure_ascii=False, indent=2)}

è¨­å‚™è³‡è¨Šï¼š
{json.dumps(devices_summary, ensure_ascii=False, indent=2)}

çµ±è¨ˆï¼š
- {len(schools_list)} æ‰€å­¸æ ¡
- {statistics.get('total_students', 0)} ä½å­¸ç”Ÿ
- {', '.join(statistics.get('counties_covered', []))}

## ğŸ’¼ å®¢æˆ¶éœ€æ±‚

{json.dumps(user_params, ensure_ascii=False, indent=2)}

---

æ’°å¯«æè´ˆç­–ç•¥åˆ†æå ±å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰ã€‚

å ±å‘Šæ’°å¯«è¦æ±‚ï¼š

1. é–‹å ´ï¼šå°ˆæ¥­åœ°åˆ†æç•¶å‰ç‹€æ³å’Œæ©Ÿæœƒ

2. **å¿…é ˆæä¾›3ç¨®æè´ˆæ–¹æ¡ˆ**ï¼š
   - æ–¹æ¡ˆAï¼šé›†ä¸­æŠ•æ”¾ç­–ç•¥
   - æ–¹æ¡ˆBï¼šåˆ†æ•£æŠ•æ”¾ç­–ç•¥  
   - æ–¹æ¡ˆCï¼šåˆ†å±¤æŠ•æ”¾ç­–ç•¥
   
   æ¯å€‹æ–¹æ¡ˆå¿…é ˆåŒ…å«ï¼š
   - æ¨è–¦å­¸æ ¡åˆ—è¡¨ï¼ˆè¡¨æ ¼æ ¼å¼ï¼Œå«å­¸æ ¡åç¨±ã€å­¸ç”Ÿæ•¸ã€ç­ç´šæ•¸ã€ç¾æœ‰è¨­å‚™ç­‰ï¼‰
   - å…·é«”è³‡æºåˆ†é…æ–¹å¼
   - å„ªç¼ºé»åˆ†æ
   - é‡åŒ–é æœŸæ•ˆç›Š

3. åŸ·è¡Œå»ºè­°èˆ‡å¾ŒçºŒæ”¯æ´

æ’°å¯«åŸå‰‡ï¼š
- ä»¥å°ˆæ¥­é¡§å•çš„å£å»ï¼Œè‡ªä¿¡ä¸”æ¬Šå¨
- å„ªå…ˆä½¿ç”¨æä¾›çš„çœŸå¯¦æ•¸æ“š
- å¦‚æ•¸æ“šä¸è¶³ï¼ŒåŸºæ–¼å°ç£åé„‰æ•™è‚²ç¾æ³å’Œå°ˆæ¥­åˆ¤æ–·ï¼Œçµ¦å‡ºåˆç†çš„å­¸æ ¡æ¨è–¦å’Œåˆ†æ
- ç¢ºä¿æ‰€æœ‰æ•¸æ“šå’Œå»ºè­°éƒ½é¡¯å¾—å°ˆæ¥­å¯ä¿¡
- ä¸è¦æåŠæ•¸æ“šä¾†æºçš„å±€é™æ€§æˆ–ä¸ç¢ºå®šæ€§
- ç”¨Markdownæ ¼å¼ï¼Œè¡¨æ ¼è¦æ¸…æ™°å®Œæ•´
"""
        
        try:
            response_text = self._call_with_retry(prompt)
            return response_text
        except Exception as e:
            print(f"[AIæœå‹™] å ±å‘Šç”Ÿæˆå¤±æ•—: {e}")
            return f"## å ±å‘Šç”Ÿæˆå¤±æ•—\n\néŒ¯èª¤ä¿¡æ¯: {str(e)}"


# å‰µå»ºå…¨å±€ AI æœå‹™å¯¦ä¾‹ï¼ˆå»¶é²åˆå§‹åŒ–ï¼‰
_ai_service_instance = None

def get_ai_service() -> AIService:
    """ç²å– AI æœå‹™å¯¦ä¾‹"""
    global _ai_service_instance
    if _ai_service_instance is None:
        _ai_service_instance = AIService()
    return _ai_service_instance

